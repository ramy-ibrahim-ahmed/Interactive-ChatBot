{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84f205fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aabb445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 60 | Classes: {'restaurant': 0, 'sales': 1, 'customers': 2, 'real_estate': 3}\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"restaurant\": [\n",
    "        \"Ø§Ø³ØªÙ‚Ø¨Ù„ Ø§Ù„Ù…Ø·Ø¹Ù… Ø£ÙƒØ«Ø± Ù…Ù† 200 Ø·Ù„Ø¨ Ø®Ù„Ø§Ù„ Ø§Ù„ÙŠÙˆÙ….\",\n",
    "        \"ØªÙ… ØªØ­Ø¯ÙŠØ« Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø·Ø¹Ø§Ù… Ø¨Ø¥Ø¶Ø§ÙØ© ÙˆØ¬Ø¨Ø§Øª Ù†Ø¨Ø§ØªÙŠØ© Ø¬Ø¯ÙŠØ¯Ø©.\",\n",
    "        \"Ù†ÙØ¯ Ù…Ø®Ø²ÙˆÙ† Ø§Ù„Ø£Ø±Ø² ÙˆØªÙ… Ø¥Ø±Ø³Ø§Ù„ ØªÙ†Ø¨ÙŠÙ‡ Ø¥Ù„Ù‰ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø´ØªØ±ÙŠØ§Øª.\",\n",
    "        \"Ø£ÙØ¶ÙŠÙ Ù…ÙˆØ¸Ù Ø¬Ø¯ÙŠØ¯ Ø¥Ù„Ù‰ Ù‚Ø³Ù… Ø§Ù„ØªÙˆØµÙŠÙ„.\",\n",
    "        \"ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø²ÙŠØ§Ø¯Ø© ÙÙŠ Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø®Ù„Ø§Ù„ Ø¹Ø·Ù„Ø© Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ Ø¨Ù†Ø³Ø¨Ø© 35%.\",\n",
    "        \"Ø§ÙƒØªØ´Ù Ø§Ù„Ù†Ø¸Ø§Ù… ØªØ£Ø®ÙŠØ±Ø§Ù‹ ÙÙŠ ØªÙˆØµÙŠÙ„ Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ø­ÙŠ Ø§Ù„Ø¬Ù†ÙˆØ¨ÙŠ.\",\n",
    "        \"ØªÙ…Øª Ù…Ø²Ø§Ù…Ù†Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª Ù…Ø¹ Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø§Ø³Ø¨Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹.\",\n",
    "        \"Ø£ÙØ¬Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ù„Ø£ÙƒØ«Ø± Ø§Ù„Ø£Ø·Ø¨Ø§Ù‚ Ù…Ø¨ÙŠØ¹Ø§Ù‹ Ø®Ù„Ø§Ù„ Ø§Ù„Ø´Ù‡Ø±.\",\n",
    "        \"ØªÙ… Ø¥ØµØ¯Ø§Ø± ØªÙ‚Ø±ÙŠØ± Ø¨Ø§Ù„Ø£Ø±Ø¨Ø§Ø­ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠØ© ÙˆØ¥Ø±Ø³Ø§Ù„Ù‡ Ø¥Ù„Ù‰ Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©.\",\n",
    "        \"Ø¨Ø¯Ø£ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø¬Ø±Ø¯ Ø§Ù„Ø¢Ù„ÙŠ Ù„Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„ØºØ°Ø§Ø¦ÙŠØ©.\",\n",
    "        \"ØªÙ…Øª Ø§Ù„Ù…ÙˆØ§ÙÙ‚Ø© Ø¹Ù„Ù‰ Ø·Ù„Ø¨ Ø´Ø±Ø§Ø¡ Ù…ÙƒÙˆÙ†Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„Ù…Ø·Ø¹Ù….\",\n",
    "        \"Ø£Ø¨Ù„Øº Ø§Ù„Ù†Ø¸Ø§Ù… Ø¹Ù† Ù†Ù‚Øµ ÙÙŠ Ø¨Ø¹Ø¶ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù…Ø«Ù„ Ø§Ù„Ø¬Ø¨Ù† ÙˆØ§Ù„Ø²ÙŠØª.\",\n",
    "        \"Ø¬Ø±Ù‰ Ø±Ø¨Ø· Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ø®Ø¯Ù…Ø© ØªÙˆØµÙŠÙ„ Ø¬Ø¯ÙŠØ¯Ø© Ù„ØªØ­Ø³ÙŠÙ† Ø³Ø±Ø¹Ø© Ø§Ù„Ø·Ù„Ø¨Ø§Øª.\",\n",
    "        \"Ø£ÙØ¶ÙŠÙØª Ø®Ø§ØµÙŠØ© ØªØªØ¨Ø¹ Ø§Ù„Ø·Ø¨Ø§Ø®ÙŠÙ† Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„ÙØ¹Ù„ÙŠ.\",\n",
    "        \"Ø£Ù†Ø´Ø£ Ø§Ù„Ù…Ø¯ÙŠØ± Ø­Ù…Ù„Ø© Ø®ØµÙˆÙ…Ø§Øª Ø¹Ø¨Ø± Ø§Ù„Ù†Ø¸Ø§Ù… Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª ÙÙŠ Ø§Ù„Ù…Ø³Ø§Ø¡.\",\n",
    "    ],\n",
    "    \"sales\": [\n",
    "        \"ØªÙ… ØªØ³Ø¬ÙŠÙ„ 50 ØµÙÙ‚Ø© Ø¨ÙŠØ¹ Ø¬Ø¯ÙŠØ¯Ø© Ù‡Ø°Ø§ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹.\",\n",
    "        \"Ø£Ù†Ø´Ø£ Ø§Ù„Ù†Ø¸Ø§Ù… ØªÙ‚Ø±ÙŠØ±Ø§Ù‹ Ù…ÙØµÙ„Ø§Ù‹ Ø¹Ù† Ø£Ø¯Ø§Ø¡ Ù…Ù†Ø¯ÙˆØ¨ÙŠ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª.\",\n",
    "        \"ØªÙ…Øª Ù…Ø²Ø§Ù…Ù†Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø§Ù„Ù…Ø­ØªÙ…Ù„ÙŠÙ† Ù…Ø¹ Ù†Ø¸Ø§Ù… Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡.\",\n",
    "        \"Ø§Ù†Ø®ÙØ¶Øª Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª ÙÙŠ Ø§Ù„Ø±Ø¨Ø¹ Ø§Ù„Ø£Ø®ÙŠØ± Ø¨Ù†Ø³Ø¨Ø© 12% Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ø§Ù„Ø±Ø¨Ø¹ Ø§Ù„Ø³Ø§Ø¨Ù‚.\",\n",
    "        \"ØªÙ… Ø¥Ø·Ù„Ø§Ù‚ Ø­Ù…Ù„Ø© ØªØ³ÙˆÙŠÙ‚ÙŠØ© Ø±Ù‚Ù…ÙŠØ© Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ÙˆØ¹ÙŠ Ø¨Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©.\",\n",
    "        \"Ø­Ø¯Ø¯ Ø§Ù„Ù†Ø¸Ø§Ù… 10 ÙØ±Øµ Ù…Ø¨ÙŠØ¹Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙˆÙ‚.\",\n",
    "        \"ØªÙ… ØªØ­Ø¯ÙŠØ« Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ù„ØªØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ Ø§Ù„ØªØºÙŠØ±Ø§Øª ÙÙŠ Ø§Ù„Ø³ÙˆÙ‚.\",\n",
    "        \"Ø£ÙØ±Ø³Ù„Øª Ø¥Ø´Ø¹Ø§Ø±Ø§Øª Ù„Ù…Ù†Ø¯ÙˆØ¨ÙŠ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª Ø­ÙˆÙ„ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ ØºÙŠØ± Ø§Ù„Ù…ØªØ§Ø¨Ø¹ÙŠÙ†.\",\n",
    "        \"Ø­Ù‚Ù‚ Ø§Ù„ÙØ±ÙŠÙ‚ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù Ù†Ø³Ø¨Ø© Ø¥Ù†Ø¬Ø§Ø² Ø¨Ù„ØºØª 95% Ù…Ù† Ø§Ù„Ø£Ù‡Ø¯Ø§Ù Ø§Ù„Ø´Ù‡Ø±ÙŠØ©.\",\n",
    "        \"ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ† ÙˆØ¥Ø¶Ø§ÙØ© Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©.\",\n",
    "        \"Ø£Ù†Ø´Ø£ Ø§Ù„Ù†Ø¸Ø§Ù… Ù…Ø®Ø·Ø·Ø§Ù‹ Ø¨ÙŠØ§Ù†ÙŠØ§Ù‹ Ù„Ù„Ù…Ø¨ÙŠØ¹Ø§Øª Ø§Ù„ÙŠÙˆÙ…ÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ù…Ù†Ø·Ù‚Ø©.\",\n",
    "        \"ØªÙ… Ø§ÙƒØªØ´Ø§Ù ØªØ±Ø§Ø¬Ø¹ ÙÙŠ Ù…Ø¨ÙŠØ¹Ø§Øª Ù…Ù†ØªØ¬ Ù…Ø­Ø¯Ø¯ ÙˆØ§Ù‚ØªÙØ±Ø­ Ø®ØµÙ… ØªØ±ÙˆÙŠØ¬ÙŠ.\",\n",
    "        \"Ø¬Ø±Ù‰ Ø¯Ù…Ø¬ Ø§Ù„Ù†Ø¸Ø§Ù… Ù…Ø¹ ØªØ·Ø¨ÙŠÙ‚ Ù†Ù‚Ø§Ø· Ø§Ù„ÙˆÙ„Ø§Ø¡ Ù„ØªØ¹Ø²ÙŠØ² Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©.\",\n",
    "        \"ØªÙ… Ø¥Ø¹Ø¯Ø§Ø¯ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø±Ø¨Ø§Ø­ ÙˆØ§Ù„Ø®Ø³Ø§Ø¦Ø± ÙˆØ¥Ø±Ø³Ø§Ù„Ù‡ Ø¥Ù„Ù‰ Ø§Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¹Ù„ÙŠØ§.\",\n",
    "        \"ØªÙ…Øª Ø£Ø±Ø´ÙØ© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ù„ØªØ­Ø³ÙŠÙ† Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ø¸Ø§Ù….\",\n",
    "    ],\n",
    "    \"customers\": [\n",
    "        \"ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© 120 Ø¹Ù…ÙŠÙ„Ø§Ù‹ Ø¬Ø¯ÙŠØ¯Ø§Ù‹ Ø®Ù„Ø§Ù„ Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ.\",\n",
    "        \"Ø£Ø±Ø³Ù„ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ø³ØªØ¨ÙŠØ§Ù† Ø±Ø¶Ø§ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø¨Ø¹Ø¯ ÙƒÙ„ Ø¹Ù…Ù„ÙŠØ© Ø´Ø±Ø§Ø¡.\",\n",
    "        \"ØªÙ… ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙˆØ§ØµÙ„ Ù„Ø¹Ø¯Ø¯ Ù…Ù† Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø§Ù„Ù‚Ø¯Ø§Ù…Ù‰.\",\n",
    "        \"Ø£Ø¸Ù‡Ø± Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø£Ù† Ù†Ø³Ø¨Ø© Ø§Ù„ÙˆÙ„Ø§Ø¡ Ø§Ø±ØªÙØ¹Øª Ø¨Ù†Ø³Ø¨Ø© 15%.\",\n",
    "        \"Ù‚Ø§Ù… ÙØ±ÙŠÙ‚ Ø§Ù„Ø¯Ø¹Ù… Ø¨Ø­Ù„ 95% Ù…Ù† Ø§Ù„Ø´ÙƒØ§ÙˆÙ‰ Ø®Ù„Ø§Ù„ Ø£ÙˆÙ„ 24 Ø³Ø§Ø¹Ø©.\",\n",
    "        \"Ø£Ø·Ù„Ù‚ Ø§Ù„Ù†Ø¸Ø§Ù… Ø­Ù…Ù„Ø© Ø´ÙƒØ± Ù„Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø§Ù„Ù…Ù…ÙŠØ²ÙŠÙ†.\",\n",
    "        \"ØªÙ… ØªØµÙ†ÙŠÙ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø­Ø³Ø¨ Ø³Ù„ÙˆÙƒ Ø§Ù„Ø´Ø±Ø§Ø¡ ÙˆØªÙƒØ±Ø§Ø± Ø§Ù„ØªØ¹Ø§Ù…Ù„.\",\n",
    "        \"ØªÙ„Ù‚Ù‰ Ø§Ù„Ø¹Ù…ÙŠÙ„ ØªÙ†Ø¨ÙŠÙ‡Ù‹Ø§ Ø¨Ø´Ø£Ù† Ø¹Ø±Ø¶ Ø®Ø§Øµ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„ØªÙŠ ÙŠÙØ¶Ù„Ù‡Ø§.\",\n",
    "        \"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø§Ø±ÙŠØ± Ø´Ù‡Ø±ÙŠØ© Ù„ØªÙ‚ÙŠÙŠÙ… Ø±Ø¶Ø§ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡.\",\n",
    "        \"Ù‚Ø§Ù… Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ø¯Ù…Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ù…Ù† ÙˆØ³Ø§Ø¦Ù„ Ø§Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ.\",\n",
    "        \"ØªÙ… ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø°ÙˆÙŠ Ø§Ù„Ø¥Ù†ÙØ§Ù‚ Ø§Ù„Ø¹Ø§Ù„ÙŠ ÙˆØ¥Ø±Ø³Ø§Ù„ Ø¹Ø±ÙˆØ¶ Ù…Ø®ØµØµØ© Ù„Ù‡Ù….\",\n",
    "        \"Ø¬Ø±Ù‰ ØªØ­Ù„ÙŠÙ„ ØªÙØ§Ø¹Ù„Ø§Øª Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©.\",\n",
    "        \"Ø£Ø¶Ø§Ù Ø§Ù„Ù†Ø¸Ø§Ù… Ø®Ø§ØµÙŠØ© Ø§Ù„ØªÙˆØµÙŠØ© Ø§Ù„Ø°ÙƒÙŠØ© Ø¨Ø§Ù„Ø¹Ø±ÙˆØ¶ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ù„ÙƒÙ„ Ø¹Ù…ÙŠÙ„.\",\n",
    "        \"ØªÙ… ØªÙ†ÙÙŠØ° Ø­Ù…Ù„Ø© Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ ØºÙŠØ± Ø§Ù„Ù†Ø´Ø·ÙŠÙ†.\",\n",
    "        \"Ø£ØµØ¯Ø± Ø§Ù„Ù†Ø¸Ø§Ù… ØªÙ†Ø¨ÙŠÙ‡Ù‹Ø§ Ø¨Ø§Ù†Ø®ÙØ§Ø¶ Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªÙØ§Ø¹Ù„ ÙÙŠ Ù…Ù†Ø·Ù‚Ø© Ù…Ø­Ø¯Ø¯Ø©.\",\n",
    "    ],\n",
    "    \"real_estate\": [\n",
    "        \"ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© 30 ÙˆØ­Ø¯Ø© Ø¹Ù‚Ø§Ø±ÙŠØ© Ø¬Ø¯ÙŠØ¯Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù†Ø¸Ø§Ù….\",\n",
    "        \"Ø§Ù†ØªÙ‡Ù‰ Ø¹Ù‚Ø¯ Ø§Ù„Ø¥ÙŠØ¬Ø§Ø± Ù„Ø®Ù…Ø³Ø© Ù…Ø³ØªØ£Ø¬Ø±ÙŠÙ† ÙˆØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø¥Ø´Ø¹Ø§Ø±Ø§Øª Ø§Ù„ØªØ¬Ø¯ÙŠØ¯.\",\n",
    "        \"ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø¯ÙØ¹Ø§Øª Ø§Ù„Ø¥ÙŠØ¬Ø§Ø± Ù„Ø´Ù‡Ø± Ø£ÙƒØªÙˆØ¨Ø± ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹.\",\n",
    "        \"Ø¨Ø¯Ø£Øª Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØµÙŠØ§Ù†Ø© Ø§Ù„Ø¯ÙˆØ±ÙŠØ© Ù„Ù„Ø¹Ù‚Ø§Ø±Ø§Øª Ø§Ù„Ø³ÙƒÙ†ÙŠØ©.\",\n",
    "        \"Ø£Ø¶Ø§Ù Ø§Ù„Ù†Ø¸Ø§Ù… Ù…ÙŠØ²Ø© ØªØªØ¨Ø¹ Ø­Ø§Ù„Ø© Ø§Ù„Ø¹Ù‚ÙˆØ¯ Ø§Ù„Ù†Ø´Ø·Ø© ÙˆØ§Ù„Ù…Ù†ØªÙ‡ÙŠØ©.\",\n",
    "        \"ØªÙ… Ø¥ØµØ¯Ø§Ø± ØªÙ‚Ø±ÙŠØ± Ø¨Ø§Ù„Ø£Ø±Ø¨Ø§Ø­ Ø§Ù„Ø´Ù‡Ø±ÙŠØ© Ù„Ù„Ø¹Ù‚Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø¤Ø¬Ø±Ø©.\",\n",
    "        \"Ø¬Ø±Ù‰ ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù„Ø§Ùƒ ÙˆØ§Ù„Ù…Ø³ØªØ£Ø¬Ø±ÙŠÙ† ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.\",\n",
    "        \"ØªÙ… Ø§ÙƒØªØ´Ø§Ù ØªØ£Ø®ÙŠØ± ÙÙŠ Ø³Ø¯Ø§Ø¯ Ø¯ÙØ¹Ø§Øª Ø£Ø­Ø¯ Ø§Ù„Ù…Ø³ØªØ£Ø¬Ø±ÙŠÙ†.\",\n",
    "        \"Ø£Ø±Ø³Ù„ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¥Ø´Ø¹Ø§Ø±Ø§Ù‹ Ù„Ù„ÙØ±ÙŠÙ‚ Ø§Ù„Ù…Ø§Ù„ÙŠ Ø­ÙˆÙ„ Ø§Ù„Ø¹Ù‚ÙˆØ¯ Ø§Ù„Ù…ØªØ£Ø®Ø±Ø©.\",\n",
    "        \"ØªÙ… Ø¬Ø¯ÙˆÙ„Ø© Ø²ÙŠØ§Ø±Ø© ØªÙÙ‚Ø¯ÙŠØ© Ù„Ø£Ø­Ø¯ Ø§Ù„Ø£Ø¨Ø±Ø§Ø¬ Ø§Ù„ØªØ¬Ø§Ø±ÙŠØ©.\",\n",
    "        \"Ø£Ø¶Ø§Ù Ø§Ù„Ù†Ø¸Ø§Ù… Ø®Ø±ÙŠØ·Ø© ØªÙØ§Ø¹Ù„ÙŠØ© Ù„Ø¹Ø±Ø¶ Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ø¹Ù‚Ø§Ø±Ø§Øª.\",\n",
    "        \"ØªÙ… Ø±Ø¨Ø· Ø§Ù„Ù†Ø¸Ø§Ù… Ù…Ø¹ Ø¨ÙˆØ§Ø¨Ø© Ø§Ù„Ø¯ÙØ¹ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„ØªØ­ØµÙŠÙ„.\",\n",
    "        \"Ø¬Ø±Ù‰ ØªØ­Ù„ÙŠÙ„ Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ø´ØºØ§Ù„ Ù„Ù„Ø¹Ù‚Ø§Ø±Ø§Øª Ø®Ù„Ø§Ù„ Ø§Ù„Ø±Ø¨Ø¹ Ø§Ù„Ø£Ø®ÙŠØ±.\",\n",
    "        \"Ø£ØµØ¯Ø± Ø§Ù„Ù†Ø¸Ø§Ù… ØªÙˆØµÙŠØ© Ø¨Ø±ÙØ¹ Ø§Ù„Ø¥ÙŠØ¬Ø§Ø± Ù„Ø¹Ù‚Ø§Ø±Ø§Øª Ø°Ø§Øª Ø·Ù„Ø¨ Ù…Ø±ØªÙØ¹.\",\n",
    "        \"ØªÙ… Ø£Ø±Ø´ÙØ© Ø§Ù„Ø¹Ù‚ÙˆØ¯ Ø§Ù„Ù…Ù†ØªÙ‡ÙŠØ© ÙˆØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ.\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "texts, labels = [], []\n",
    "label2id = {label: idx for idx, label in enumerate(data.keys())}\n",
    "for label, examples in data.items():\n",
    "    texts.extend(examples)\n",
    "    labels.extend([label2id[label]] * len(examples))\n",
    "\n",
    "print(f\"Total samples: {len(texts)} | Classes: {label2id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "267832f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cohere import AsyncClientV2\n",
    "\n",
    "\n",
    "def normalize_embeddings(embeddings):\n",
    "    norm = torch.norm(torch.tensor(embeddings), dim=1, keepdim=True)\n",
    "    return (torch.tensor(embeddings) / norm).tolist()\n",
    "\n",
    "\n",
    "class BaseEmbeddings:\n",
    "    pass\n",
    "\n",
    "\n",
    "class CohereEmbeddings(BaseEmbeddings):\n",
    "    def __init__(self, cohere_client):\n",
    "        self.cohere_client = cohere_client\n",
    "\n",
    "    async def embed(\n",
    "        self,\n",
    "        list_of_text: list[str],\n",
    "        model_name=\"embed-v4.0\",\n",
    "        batch_size=10,\n",
    "    ) -> list[list[float]]:\n",
    "        vectors = []\n",
    "        for i in range(0, len(list_of_text), batch_size):\n",
    "            batch = list_of_text[i : i + batch_size]\n",
    "            response = await self.cohere_client.embed(\n",
    "                texts=batch,\n",
    "                model=model_name,\n",
    "                input_type=\"search_document\",\n",
    "                embedding_types=[\"float\"],\n",
    "                output_dimension=1024,\n",
    "            )\n",
    "            batch_vectors = response.embeddings.float\n",
    "            normalized = normalize_embeddings(batch_vectors)\n",
    "            vectors.extend(normalized)\n",
    "        return vectors\n",
    "\n",
    "\n",
    "async def generate_embeddings():\n",
    "    cohere_client = AsyncClientV2(\"q5K7ogyRXviI1pCR4PeTqvvjFyVGLkHvfwlv6EmE\")\n",
    "    embedder = CohereEmbeddings(cohere_client)\n",
    "    embeddings = await embedder.embed(texts)\n",
    "    return torch.tensor(embeddings, dtype=torch.float32), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a015e7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_classes, hidden_dim=512, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feced2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    X, y = await generate_embeddings()\n",
    "    dataset = TensorDataset(X, y)\n",
    "    dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "    model = EmbeddingClassifier(embedding_dim=1024, num_classes=4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    num_epochs = 10\n",
    "    epoch_pbar = tqdm(range(num_epochs), desc=\"Training Progress\")\n",
    "\n",
    "    for epoch in epoch_pbar:\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        batch_pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "\n",
    "        for X_batch, y_batch in batch_pbar:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            batch_pbar.set_postfix({\"batch_loss\": f\"{loss.item():.4f}\"})\n",
    "        avg_epoch_loss = running_loss / len(dataloader)\n",
    "        epoch_pbar.set_postfix({\"avg_epoch_loss\": f\"{avg_epoch_loss:.4f}\"})\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b1fcbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  8.79it/s, avg_epoch_loss=0.0161]\n"
     ]
    }
   ],
   "source": [
    "model = await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "532775ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Class: sales | ðŸ”¥ Confidence: 0.87\n"
     ]
    }
   ],
   "source": [
    "label_map = {0: \"restaurant\", 1: \"sales\", 2: \"customers\", 3: \"real_estate\"}\n",
    "\n",
    "\n",
    "async def classify_query(\n",
    "    query: str, model, embedder: CohereEmbeddings, label_map: dict\n",
    "):\n",
    "    query_emb = await embedder.embed([query])\n",
    "    query_tensor = torch.tensor(query_emb, dtype=torch.float32)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(query_tensor)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        predicted_idx = probs.argmax(dim=1).item()\n",
    "\n",
    "    predicted_label = label_map[predicted_idx]\n",
    "    confidence = probs[0][predicted_idx].item()\n",
    "\n",
    "    return predicted_label, confidence\n",
    "\n",
    "\n",
    "cohere_client = AsyncClientV2(\"q5K7ogyRXviI1pCR4PeTqvvjFyVGLkHvfwlv6EmE\")\n",
    "embedder = CohereEmbeddings(cohere_client)\n",
    "label_map = {0: \"restaurant\", 1: \"sales\", 2: \"customers\", 3: \"real_estate\"}\n",
    "query = \"Ø£Ø·Ù„Ù‚Øª Ø§Ù„Ø´Ø±ÙƒØ© Ø­Ù…Ù„Ø© ØªØ±ÙˆÙŠØ¬ÙŠØ© Ø¬Ø¯ÙŠØ¯Ø© Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª.\"\n",
    "label, conf = await classify_query(query, model, embedder, label_map)\n",
    "print(f\"ðŸ“Š Class: {label} | ðŸ”¥ Confidence: {conf:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onyx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
