{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8309e9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.graph.workflow import init_workflow\n",
    "from src.store.nlp import NLPFactory\n",
    "from src.store.vectordb import VectorDBFactory\n",
    "from src.core.config import get_settings\n",
    "\n",
    "SETTINGS = get_settings()\n",
    "\n",
    "nlp_openai = NLPFactory.create(provider=\"openai\")\n",
    "nlp_gemini = NLPFactory.create(provider=\"gemini\")\n",
    "nlp_cohere = NLPFactory.create(provider=\"cohere\")\n",
    "vectordb_factory = VectorDBFactory()\n",
    "vectordb = vectordb_factory.create(provider=\"pinecone\", settings=SETTINGS)\n",
    "vectordb.connect()\n",
    "workflow = init_workflow(nlp_openai, nlp_gemini, nlp_cohere, vectordb)\n",
    "\n",
    "query = \"ازاي احسب اجمالي هامش الربح؟\"\n",
    "# namespace = \"customers_chunking_rewrite\"\n",
    "namespace = \"customers_chunk_fixed\"\n",
    "res = \"\"\n",
    "for event in workflow.stream({\"user_message\": query, \"namespace\": namespace}):\n",
    "    print(event)\n",
    "    if event.get(\"chat\"):\n",
    "        res = event[\"chat\"][\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d787ffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(f\"<div dir='rtl'>{res}</div>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1052c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5742400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc04bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ba3c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "import pyarabic.araby as araby\n",
    "from tqdm.auto import tqdm\n",
    "from pinecone_text.sparse import BM25Encoder\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"stopwords\")  # Downloads stopwords, including Arabic\n",
    "\n",
    "# --- Your existing setup code (mostly unchanged) ---\n",
    "\n",
    "\n",
    "PINECONE_API_KEY = (\n",
    "    \"pcsk_5Ho56W_T3c3KLAQZBEVoqBueWma8j2C7MjfWrgzUrT3mHmGgxKAihEX4kGgtbp9RErcqot\"\n",
    ")\n",
    "PINECONE_HOST = \"https://onyx-sparse-bxkmeye.svc.aped-4627-b74a.pinecone.io\"\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY, host=PINECONE_HOST)\n",
    "index = pc.Index(host=PINECONE_HOST)\n",
    "\n",
    "# Initialize BM25 without language (we'll override tokenizer)\n",
    "bm25 = BM25Encoder()\n",
    "\n",
    "\n",
    "# Custom tokenizer for Arabic: Tokenize, stem, remove stopwords and short tokens\n",
    "def arabic_tokenizer(text):\n",
    "    tokens = araby.tokenize(text)\n",
    "    stemmer = ISRIStemmer()\n",
    "    arabic_stopwords = set(nltk.corpus.stopwords.words(\"arabic\"))\n",
    "    return [stemmer.stem(t) for t in tokens if t not in arabic_stopwords and len(t) > 1]\n",
    "\n",
    "\n",
    "# Override the default tokenizer\n",
    "bm25._tokenizer = arabic_tokenizer\n",
    "\n",
    "\n",
    "def preprocess_arabic(text):\n",
    "    text = araby.strip_tashkeel(text)\n",
    "    text = araby.normalize_alef(text)\n",
    "    text = araby.normalize_hamza(text)\n",
    "    text = araby.strip_tatweel(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "documents = [\n",
    "    \"القاهرة هي عاصمة جمهورية مصر العربية وأكبر مدنها.\",\n",
    "    \"الذكاء الاصطناعي هو فرع من علوم الحاسوب يهدف إلى إنشاء آلات ذكية.\",\n",
    "    \"تعتبر الأهرامات في الجيزة من عجائب الدنيا السبع القديمة.\",\n",
    "    \"يعمل التعلم الآلي على تحليل البيانات وبناء النماذج التنبؤية.\",\n",
    "    \"النيل هو أطول نهر في العالم ويمر عبر العديد من الدول الأفريقية.\",\n",
    "    \"تستخدم الشبكات العصبية في تطبيقات التعرف على الصور ومعالجة اللغات الطبيعية.\",\n",
    "]\n",
    "processed_docs = [preprocess_arabic(doc) for doc in documents]\n",
    "\n",
    "# Fit the BM25 encoder on your documents before encoding\n",
    "print(\"Fitting BM25 encoder...\")\n",
    "bm25.fit(processed_docs)\n",
    "print(\"Fit complete.\")\n",
    "\n",
    "vectors_to_upsert = []\n",
    "\n",
    "for i, doc in enumerate(tqdm(processed_docs)):\n",
    "    sparse_vector = bm25.encode_documents(doc)\n",
    "    vectors_to_upsert.append(\n",
    "        {\n",
    "            \"id\": str(i),\n",
    "            \"sparse_values\": sparse_vector,\n",
    "            \"metadata\": {\"text\": documents[i]},\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Upsert in batches for better performance, especially with more data\n",
    "# For this small example, a single upsert is fine.\n",
    "index.upsert(vectors=vectors_to_upsert, namespace=\"customers-sparse\")\n",
    "print(\"Upsert complete.\")\n",
    "\n",
    "\n",
    "def search(query):\n",
    "    processed_query = preprocess_arabic(query)\n",
    "    sparse_qv = bm25.encode_queries(processed_query)\n",
    "    result = index.query(sparse_vector=sparse_qv, top_k=3, include_metadata=True, namespace=\"customers-sparse\")\n",
    "    print(f\"\\nSearch results for: '{query}'\")\n",
    "    for match in result[\"matches\"]:\n",
    "        print(f\"  Score: {match['score']:.4f}, Text: {match['metadata']['text']}\")\n",
    "\n",
    "\n",
    "# --- Your search calls (unchanged) ---\n",
    "search(\"الشبكات العصبية والتعرف على الصور\")\n",
    "search(\"ما هي المدينة الرئيسية في مصر؟\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebca948c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ramyu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to Pinecone.\n",
      "Loading BM25 model from file...\n",
      "BM25 model loaded successfully.\n",
      "\n",
      "Searching for: 'محركات البحث'\n",
      "Encoding query...\n",
      "Querying Pinecone index...\n",
      "Found keywords: ['{\"page_start\": 122, \"page_end\": 122, \"chapter\": \"نظام العملاء (أونكس أي إكس) ERP\"}\\n\\n### [Chapter: نظام العملاء - Section: البيانات التفصيلية]\\n\\n#### ثامنا: البيانات التفصيلية\\n\\n**ملاحظة**: حيث أن البيانات الأساسية تمثل الطرف المدين للقيد سواء طرف واحد أو متعدد الأطراف، بينما تمثل البيانات التفصيلية الجانب الدائن.\\n\\n##### - رقم/اسم الحساب\\n\\nيستخدم هذا الحقل لاختيار رقم الحساب \"الدائن\" بواسطة الضغط على زر (F9) أو إدخاله يدوياً، وبمجرد اختيار الحساب يظهر الاسم في الحقل المخصص له، ويمكن البحث عن الحساب في قائمة الحسابات برمز الحساب أو جزء منه أو اسمه أو جزء من الاسم في حقل البحث.\\n\\n###### ملاحظة عامة\\n\\nتظهر في الحقول الخاصة بإدخال رقم الحساب - سواء رئيسي أو تحليلي أو تحليلي فرعي - في جميع شاشات النظام بعض المفاتيح المساعدة التي تقوم بمهام ووظائف معينة، وتظهر هذه المفاتيح أسفل يسار الشاشة، كما أنه عند الوقوف بالسهم على حقل رقم الحساب والنقر بالزر الأيمن للفأرة تظهر قائمة بها بعض الاختصارات مثل المدخلات لعرض تصنيف الحساب في دليل الحسابات مباشرة، وعمليات لعرض حركات الحساب وعرض قائمة أو إضافة وحذف سجل F9 ,F8 ,F1 ,F2 ,F6 ,F7 ,ALT+I ,Ctrl+E.\\n\\n##### وتتلخص المفاتيح المساعدة ووظائفها كالآتي\\n\\n| مفتاح | البيان                                          |\\n| :---- | :---------------------------------------------- |\\n| F9    | لإظهار قائمة جميع الحسابات.                    |\\n| Alt+I | لعرض تصنيف الحساب في دليل الحسابات مباشرة.     |\\n| F8    | لإظهار قائمة الحسابات مرتبة باسم.              |\\n| Alt+T | للذهاب لشاشة حركة الحسابات لعرض العمليات.       |', '{\"page_start\": 108, \"page_end\": 108, \"chapter\": \"طلب سند قبض\"}\\n[Chapter طلب سند قبض - Section البيانات التفصيلية]:\\nملاحظة: البيانات الأساسية تمثل الطرف المدين للقيد سواء طرف واحد أو متعدد الأطراف، وتمثل البيانات التفصيلية الجانب الدائن للقيد.\\n\\n### رقم/ اسم الحساب\\nيستخدم هذا الحقل لاختيار رقم الحساب \"الدائن\" بواسطة الضغط على زر (F9) أو إدخاله يدوياً، وبمجرد اختيار الحساب يظهر الاسم في الحقل المخصص له، ويمكن البحث عن الحساب في قائمة الحسابات برمز الحساب أو جزء منه أو اسمه أو جزء من الاسم في حقل البحث.\\n\\nملاحظة عامة: تظهر في الحقول الخاصة بإدخال رقم الحساب في بعض شاشات النظام مفاتيح المساعدة التي تقوم بمهام ووظائف معينة، وتظهر هذه المفاتيح أسفل يسار الشاشة، كما أنه عند الوقوف بالسهم على حقل رقم الحساب والنقر بالزر الأيمن للفأرة تظهر قائمة بها بعض الاختصارات مثل المدخلات لعرض تصنيف الحساب في دليل الحسابات مباشرة، وعمليات لعرض حركات الحساب وعرض قائمة أو السجل حالي أو إضافة وحذف سجل F8 , F9 .\\n\\n* Alt+T+Alt+I', '{\"page_start\":44, \"page_end\":44, \"chapter\": \"بيانات المحصلين\"}\\n[Chapter بيانات المحصلين - Section 2.1 - البيانات الأساسية]:\\n* رقم المحصل: رقم تسلسلي يظهر آلياً حسب تهيئة التسلسلات. \\n  * ملحوظة 1: إذا كان متغير \"استخدام الأرقام فقط في رقم المحصل\" مفعلاً، يكون الرقم أرقام فقط، وإلا يمكن أن يحتوي على رموز وأحرف.\\n  * ملحوظة 2: يوجد زر حركة الحسابات بجوار الحقل لنقل المستخدم إلى شاشة \"حركة الحسابات\" لمراجعة الحركات المرتبطة بالمحصل.\\n* الوحدة المالية: ربط المحصل بالوحدة المالية إلزامي ولا يمكن إجراء عمليات إلا ضمن الوحدة المرتبطة.\\n* المحصل الرئيسي: اختيار المحصل الرئيسي من قائمة المحصلين (F9). إذا كان المحصل هو الرئيسي، يترك الحقل فارغاً.\\n* اسم المحصل / الاسم الأجنبي: إدخال اسم المحصل باللغة الافتراضية (إجباري) واسم أجنبي (اختياري).\\n* رقم المجموعة: اختيار رقم المجموعة التي ينتمي إليها المحصل (F9).']\n",
      "\n",
      "Searching for: 'الذكاء الاصطناعي'\n",
      "Encoding query...\n",
      "Querying Pinecone index...\n",
      "Found keywords: []\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import pyarabic.araby as araby\n",
    "from pinecone_text.sparse import BM25Encoder\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "import nltk\n",
    "import os\n",
    "import json\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "PINECONE_API_KEY = (\n",
    "    \"pcsk_5Ho56W_T3c3KLAQZBEVoqBueWma8j2C7MjfWrgzUrT3mHmGgxKAihEX4kGgtbp9RErcqot\"\n",
    ")\n",
    "PINECONE_HOST = \"https://onyx-sparse-bxkmeye.svc.aped-4627-b74a.pinecone.io\"\n",
    "\n",
    "\n",
    "# Connect to Pinecone\n",
    "try:\n",
    "    pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "    index = pc.Index(host=PINECONE_HOST)\n",
    "    print(\"Successfully connected to Pinecone.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to Pinecone: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Download necessary NLTK data\n",
    "try:\n",
    "    nltk.data.find(\"corpora/stopwords\")\n",
    "except nltk.downloader.DownloadError:\n",
    "    nltk.download(\"stopwords\")\n",
    "\n",
    "# --- Arabic Text Preprocessing Functions ---\n",
    "\n",
    "\n",
    "def preprocess_arabic(text):\n",
    "    \"\"\"Normalizes and cleans Arabic text.\"\"\"\n",
    "    text = araby.strip_tashkeel(text)\n",
    "    text = araby.normalize_alef(text)\n",
    "    text = araby.normalize_hamza(text)\n",
    "    text = araby.strip_tatweel(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def arabic_tokenizer(text):\n",
    "    \"\"\"\n",
    "    Tokenizes, stems, and removes stopwords from Arabic text.\n",
    "    Uses ISRIStemmer for stemming.\n",
    "    \"\"\"\n",
    "    tokens = araby.tokenize(text)\n",
    "    stemmer = ISRIStemmer()\n",
    "    arabic_stopwords = set(nltk.corpus.stopwords.words(\"arabic\"))\n",
    "    return [stemmer.stem(t) for t in tokens if t not in arabic_stopwords and len(t) > 1]\n",
    "\n",
    "\n",
    "# --- Load the BM25 Encoder ---\n",
    "\n",
    "print(\"Loading BM25 model from file...\")\n",
    "# **FIX:** The error indicates 'bm25_values.json' might be malformed or from an\n",
    "# older version. This code robustly loads it by manually checking for and\n",
    "# adding missing required parameters before initializing the encoder.\n",
    "try:\n",
    "    with open(\"bm25_values.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        params = json.load(f)\n",
    "\n",
    "    # Ensure required keys exist to prevent TypeError.\n",
    "    # This is a workaround for a malformed model file.\n",
    "    params.setdefault(\"remove_punctuation\", False)\n",
    "    params.setdefault(\"remove_stopwords\", False)\n",
    "    params.setdefault(\"stem\", False)\n",
    "\n",
    "    # Manually create the encoder and set its parameters\n",
    "    bm25 = BM25Encoder()\n",
    "    bm25.set_params(**params)\n",
    "\n",
    "    # After loading, you MUST re-assign the custom tokenizer function.\n",
    "    # The JSON file saves the *parameters* but cannot save the function object itself.\n",
    "    bm25._tokenizer = arabic_tokenizer\n",
    "    print(\"BM25 model loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\n",
    "        \"Error: 'bm25_values.json' not found. Please run 'create_bm25_model.py' first.\"\n",
    "    )\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the BM25 model: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- Search Function ---\n",
    "\n",
    "\n",
    "def search_keywords(query, top_k=5):\n",
    "    \"\"\"\n",
    "    Takes a query, processes it, encodes it with BM25, and queries Pinecone.\n",
    "    \"\"\"\n",
    "    if not query:\n",
    "        return []\n",
    "\n",
    "    print(f\"\\nSearching for: '{query}'\")\n",
    "\n",
    "    # 1. Preprocess the query text\n",
    "    processed_query = preprocess_arabic(query)\n",
    "\n",
    "    # 2. Encode the query into a sparse vector using the loaded BM25 model\n",
    "    print(\"Encoding query...\")\n",
    "    sparse_qv = bm25.encode_queries(processed_query)\n",
    "\n",
    "    # 3. Query Pinecone\n",
    "    print(\"Querying Pinecone index...\")\n",
    "    try:\n",
    "        result = index.query(\n",
    "            sparse_vector=sparse_qv,\n",
    "            top_k=top_k,\n",
    "            include_metadata=True,\n",
    "            namespace=\"customers-sparse-v1\",  # Make sure this namespace is correct\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during Pinecone query: {e}\")\n",
    "        return []\n",
    "\n",
    "    # 4. Extract keywords from metadata\n",
    "    keywords = [match[\"metadata\"][\"text\"] for match in result.get(\"matches\", [])]\n",
    "\n",
    "    print(f\"Found keywords: {keywords}\")\n",
    "    return keywords\n",
    "\n",
    "\n",
    "# --- Example Usage (similar to how a FastAPI endpoint would call it) ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # This simulates running the search function\n",
    "    test_query_1 = \"محركات البحث\"\n",
    "    search_results_1 = search_keywords(test_query_1, top_k=3)\n",
    "\n",
    "    test_query_2 = \"الذكاء الاصطناعي\"\n",
    "    search_results_2 = search_keywords(test_query_2, top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8f76cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onyx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
